# Workflow to build and test wheels
name: Wheel builder

on:
  schedule:
    # Nightly build at 3:42 A.M.
    - cron: "42 3 */1 * *"
  push:
    tags:
      # Final releases, release candidates and post-releases build
      - "[0-9]+.[0-9]+.[0-9]+(rc[0-9]+)?(.post[0-9]+)?"
  pull_request:
    branches:
      - master
      - "[0-9]+.[0-9]+.X"

jobs:
  # Check whether to trigger the build
  check_build:
    name: Check build trigger
    runs-on: ubuntu-latest
    outputs:
      build: ${{ steps.check_build.outputs.build }}

    steps:
      - name: Checkout scikit-learn
        uses: actions/checkout@v1

      - name: Set environment variables
        run: |
          echo "COMMIT_MSG=$(git log --no-merges -1 --oneline)" >> $GITHUB_ENV

      - id: check_build
        name: Check build
        if: endsWith(env.COMMIT_MSG, '[cd build]') || github.event_name == 'push'
        run: |
          echo "::set-output name=build::true"

  build_wheels:
    name: Build wheels on ${{ matrix.os }} for Python ${{ matrix.python }}
    runs-on: ${{ matrix.os }}
    needs: check_build
    if: needs.check_build.outputs.build

    strategy:
      # Avoid that the wheel builder for a
      # runner is cancelled if other fails
      fail-fast: false
      matrix:
        os: [windows-latest, ubuntu-latest, macos-latest]
        # Build the wheels for Python 3.6 and newer
        python: [36, 37, 38]

    steps:
      - name: Checkout scikit-learn
        uses: actions/checkout@v1

      - name: Setup Python
        uses: actions/setup-python@v2

      - name: Install dependencies
        shell: bash
        run: |
          # Enable OpenMP support for the compiler shipped by default with macOS
          if [ "$RUNNER_OS" == "macOS" ]
          then
            brew install libomp
            echo "CC=/usr/bin/clang" >> $GITHUB_ENV
            echo "CXX=/usr/bin/clang++" >> $GITHUB_ENV
            echo "CPPFLAGS=$CPPFLAGS -Xpreprocessor -fopenmp" >> $GITHUB_ENV
            echo "CFLAGS=$CFLAGS -I/usr/local/opt/libomp/include" >> $GITHUB_ENV
            echo "CXXFLAGS=$CXXFLAGS -I/usr/local/opt/libomp/include" >> $GITHUB_ENV
            echo "LDFLAGS=$LDFLAGS -Wl,-rpath,/usr/local/opt/libomp/lib -L/usr/local/opt/libomp/lib -lomp" >> $GITHUB_ENV
          fi
          python -m pip install cibuildwheel wheel

      # Note that the versions of the build dependencies are specified in
      # the pyproject.toml file, while the tests are run against the most
      # recent versions of the dependencies specified in the wheel metadata
      - name: Build and test wheels
        env:
          CIBW_BUILD: cp${{ matrix.python }}-*
          CIBW_TEST_REQUIRES: pytest pandas threadpoolctl
          # Run the tests and check that there are no links to system libraries
          CIBW_TEST_COMMAND: pytest --pyargs sklearn && python -m threadpoolctl -i sklearn
        run: |
          python -m cibuildwheel --output-dir wheelhouse

      - name: Vendor vcomp140.dll
        shell: bash
        if: runner.os == 'Windows'
        run: |
          for wheel in wheelhouse/*.whl
          do
            # Vendor the vcomp140.dll file but
            # repacking to generate the RECORD
            wheel unpack "$wheel"
            wheel_dirname=$(find . -maxdepth 1 -type d -name 'scikit_learn*' -print -quit)
            python build_tools/github/vendor_vcomp140.py "$wheel_dirname"
            wheel pack "$wheel_dirname" -d wheelhouse
            rm -r "$wheel_dirname"

            # Ensure that the wheel vendors vcomp140.dll
            unzip -l "$wheel" | grep -q sklearn/.libs/vcomp140.dll

            if [ "$?" == "0" ]
            then
              echo "$wheel vendors vcomp140.dll."
            else
              # Immediately exit with an error status code
              echo "$wheel does not vendor vcomp140.dll."
              exit 1
            fi
          done

      - name: Store artifacts
        uses: actions/upload-artifact@v2
        with:
          path: wheelhouse/*.whl

  build_sdist:
    name: Source distribution
    runs-on: ubuntu-latest
    needs: check_build
    if: needs.check_build.outputs.build

    steps:
      - name: Checkout scikit-learn
        uses: actions/checkout@v1

      - name: Setup Python
        uses: actions/setup-python@v2

      # The setup file and the tests need
      # these dependencies to be installed
      - name: Install dependencies
        run: |
          python -m pip install numpy scipy cython
          python -m pip install twine
          python -m pip install pytest pandas

      - name: Build and test source distribution
        run: |
          python setup.py sdist
          ls -l dist/*.tar.gz
          twine check dist/*.tar.gz
          python -m pip install dist/*.tar.gz
          python setup.py build_ext -i
          pytest --pyargs sklearn

      - name: Store artifacts
        uses: actions/upload-artifact@v2
        with:
          path: dist/*.tar.gz

  upload_anaconda:
    name: Upload to Anaconda
    runs-on: ubuntu-latest
    needs: [build_wheels, build_sdist]
    # The artifacts should not be uploaded on PRs
    if: github.event_name != 'pull_request'

    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v2
        with:
          path: dist

      - name: Display artifacts
        run: |
          ls -l dist/*

      - name: Setup Python
        uses: actions/setup-python@v2

      - name: Upload artifacts
        env:
          # Secret variables need to be mapped to environment variables explicitly
          SCIKIT_LEARN_NIGHTLY_UPLOAD_TOKEN: ${{ secrets.SCIKIT_LEARN_NIGHTLY_UPLOAD_TOKEN }}
          SCIKIT_LEARN_STAGING_UPLOAD_TOKEN: ${{ secrets.SCIKIT_LEARN_STAGING_UPLOAD_TOKEN }}
        # Force a replacement if the remote file already exists
        run: |
          if [ "$GITHUB_EVENT_NAME" == "schedule" ]; then
            ANACONDA_ORG="scipy-wheels-nightly"
            ANACONDA_TOKEN="$SCIKIT_LEARN_NIGHTLY_UPLOAD_TOKEN"
          else
            ANACONDA_ORG="scikit-learn-wheels-staging"
            ANACONDA_TOKEN="$SCIKIT_LEARN_STAGING_UPLOAD_TOKEN"
          fi
          conda install -q -y anaconda-client
          anaconda -t $ANACONDA_TOKEN upload --force -u $ANACONDA_ORG dist/*
          echo "Index: https://pypi.anaconda.org/$ANACONDA_ORG/simple"
