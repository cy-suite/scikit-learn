{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bacc48-b659-404d-b82a-82106426a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import (\n",
    "    make_blobs,\n",
    "    fetch_20newsgroups,\n",
    "    fetch_openml,\n",
    "    load_digits,\n",
    "    make_regression,\n",
    "    make_classification,\n",
    "    fetch_olivetti_faces,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd980cf3-09eb-4ac8-a2bd-e0907af08425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6023917c-c8c8-4a9e-bb8f-306f3e1dcfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=100000\n",
    "n_features=1000\n",
    "n_classes=2\n",
    "dtype=np.float32\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    n_classes=n_classes,\n",
    "    random_state=0,\n",
    "    n_informative=n_features,\n",
    "    n_redundant=0,\n",
    ")\n",
    "X = X.astype(dtype, copy=False)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd61450-7e0f-4049-95b6-a1888de0ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = -1\n",
    "\n",
    "n_estimators = 500\n",
    "\n",
    "estimator = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    min_samples_split=10,\n",
    "    max_features=\"log2\",\n",
    "    n_jobs=n_jobs,\n",
    "    random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a139cb-44d7-434e-ac4d-e8c20f5a2b87",
   "metadata": {},
   "source": [
    "## Fortran Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "590c1eed-ce59-43f9-926d-6611304fda84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /Users/adam2392/Documents/scikit-learn/sklearn/ensemble/_forest.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "   313   1494.8 MiB   1494.8 MiB           1       def fit(self, X, y, sample_weight=None):\n",
       "   314                                                 \"\"\"\n",
       "   315                                                 Build a forest of trees from the training set (X, y).\n",
       "   316                                         \n",
       "   317                                                 Parameters\n",
       "   318                                                 ----------\n",
       "   319                                                 X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
       "   320                                                     The training input samples. Internally, its dtype will be converted\n",
       "   321                                                     to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
       "   322                                                     converted into a sparse ``csc_matrix``.\n",
       "   323                                         \n",
       "   324                                                 y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
       "   325                                                     The target values (class labels in classification, real numbers in\n",
       "   326                                                     regression).\n",
       "   327                                         \n",
       "   328                                                 sample_weight : array-like of shape (n_samples,), default=None\n",
       "   329                                                     Sample weights. If None, then samples are equally weighted. Splits\n",
       "   330                                                     that would create child nodes with net zero or negative weight are\n",
       "   331                                                     ignored while searching for a split in each node. In the case of\n",
       "   332                                                     classification, splits are also ignored if they would result in any\n",
       "   333                                                     single class carrying a negative weight in either child node.\n",
       "   334                                         \n",
       "   335                                                 Returns\n",
       "   336                                                 -------\n",
       "   337                                                 self : object\n",
       "   338                                                     Fitted estimator.\n",
       "   339                                                 \"\"\"\n",
       "   340   1494.8 MiB      0.0 MiB           1           self._validate_params()\n",
       "   341                                         \n",
       "   342                                                 # Validate or convert input data\n",
       "   343   1494.8 MiB      0.0 MiB           1           if issparse(y):\n",
       "   344                                                     raise ValueError(\"sparse multilabel-indicator for y is not supported.\")\n",
       "   345   1494.8 MiB      0.0 MiB           2           X, y = self._validate_data(\n",
       "   346   1494.8 MiB      0.0 MiB           1               X, y, multi_output=True, accept_sparse=\"csc\", dtype=DTYPE\n",
       "   347                                                 )\n",
       "   348   1494.8 MiB      0.0 MiB           1           if sample_weight is not None:\n",
       "   349                                                     sample_weight = _check_sample_weight(sample_weight, X)\n",
       "   350                                         \n",
       "   351   1494.8 MiB      0.0 MiB           1           if issparse(X):\n",
       "   352                                                     # Pre-sort indices to avoid that each individual tree of the\n",
       "   353                                                     # ensemble sorts the indices.\n",
       "   354                                                     X.sort_indices()\n",
       "   355   1494.8 MiB      0.0 MiB           1           elif not X.flags.fortran:\n",
       "   356                                                     # if X is not fortran, then make a copy here and make sure it is fortran\n",
       "   357   1838.1 MiB    343.3 MiB           1               X = np.asfortranarray(X, dtype=DTYPE)\n",
       "   358                                         \n",
       "   359   1838.1 MiB      0.0 MiB           1           y = np.atleast_1d(y)\n",
       "   360   1838.1 MiB      0.0 MiB           1           if y.ndim == 2 and y.shape[1] == 1:\n",
       "   361                                                     warn(\n",
       "   362                                                         \"A column-vector y was passed when a 1d array was\"\n",
       "   363                                                         \" expected. Please change the shape of y to \"\n",
       "   364                                                         \"(n_samples,), for example using ravel().\",\n",
       "   365                                                         DataConversionWarning,\n",
       "   366                                                         stacklevel=2,\n",
       "   367                                                     )\n",
       "   368                                         \n",
       "   369   1838.1 MiB      0.0 MiB           1           if y.ndim == 1:\n",
       "   370                                                     # reshape is necessary to preserve the data contiguity against vs\n",
       "   371                                                     # [:, np.newaxis] that does not.\n",
       "   372   1838.1 MiB      0.0 MiB           1               y = np.reshape(y, (-1, 1))\n",
       "   373                                         \n",
       "   374   1838.1 MiB      0.0 MiB           1           if self.criterion == \"poisson\":\n",
       "   375                                                     if np.any(y < 0):\n",
       "   376                                                         raise ValueError(\n",
       "   377                                                             \"Some value(s) of y are negative which is \"\n",
       "   378                                                             \"not allowed for Poisson regression.\"\n",
       "   379                                                         )\n",
       "   380                                                     if np.sum(y) <= 0:\n",
       "   381                                                         raise ValueError(\n",
       "   382                                                             \"Sum of y is not strictly positive which \"\n",
       "   383                                                             \"is necessary for Poisson regression.\"\n",
       "   384                                                         )\n",
       "   385                                         \n",
       "   386   1838.1 MiB      0.0 MiB           1           self.n_outputs_ = y.shape[1]\n",
       "   387                                         \n",
       "   388   1841.0 MiB      2.9 MiB           1           y, expanded_class_weight = self._validate_y_class_weight(y)\n",
       "   389                                         \n",
       "   390   1841.0 MiB      0.0 MiB           1           if getattr(y, \"dtype\", None) != DOUBLE or not y.flags.contiguous:\n",
       "   391   1841.0 MiB      0.0 MiB           1               y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
       "   392                                         \n",
       "   393   1841.0 MiB      0.0 MiB           1           if expanded_class_weight is not None:\n",
       "   394                                                     if sample_weight is not None:\n",
       "   395                                                         sample_weight = sample_weight * expanded_class_weight\n",
       "   396                                                     else:\n",
       "   397                                                         sample_weight = expanded_class_weight\n",
       "   398                                         \n",
       "   399   1841.0 MiB      0.0 MiB           1           if not self.bootstrap and self.max_samples is not None:\n",
       "   400                                                     raise ValueError(\n",
       "   401                                                         \"`max_sample` cannot be set if `bootstrap=False`. \"\n",
       "   402                                                         \"Either switch to `bootstrap=True` or set \"\n",
       "   403                                                         \"`max_sample=None`.\"\n",
       "   404                                                     )\n",
       "   405   1841.0 MiB      0.0 MiB           1           elif self.bootstrap:\n",
       "   406   1841.0 MiB      0.0 MiB           2               n_samples_bootstrap = _get_n_samples_bootstrap(\n",
       "   407   1841.0 MiB      0.0 MiB           1                   n_samples=X.shape[0], max_samples=self.max_samples\n",
       "   408                                                     )\n",
       "   409                                                 else:\n",
       "   410                                                     n_samples_bootstrap = None\n",
       "   411                                         \n",
       "   412   1841.0 MiB      0.0 MiB           1           self._validate_estimator()\n",
       "   413   1841.0 MiB      0.0 MiB           1           if isinstance(self, (RandomForestRegressor, ExtraTreesRegressor)):\n",
       "   414                                                     # TODO(1.3): Remove \"auto\"\n",
       "   415                                                     if self.max_features == \"auto\":\n",
       "   416                                                         warn(\n",
       "   417                                                             \"`max_features='auto'` has been deprecated in 1.1 \"\n",
       "   418                                                             \"and will be removed in 1.3. To keep the past behaviour, \"\n",
       "   419                                                             \"explicitly set `max_features=1.0` or remove this \"\n",
       "   420                                                             \"parameter as it is also the default value for \"\n",
       "   421                                                             \"RandomForestRegressors and ExtraTreesRegressors.\",\n",
       "   422                                                             FutureWarning,\n",
       "   423                                                         )\n",
       "   424   1841.0 MiB      0.0 MiB           1           elif isinstance(self, (RandomForestClassifier, ExtraTreesClassifier)):\n",
       "   425                                                     # TODO(1.3): Remove \"auto\"\n",
       "   426   1841.0 MiB      0.0 MiB           1               if self.max_features == \"auto\":\n",
       "   427                                                         warn(\n",
       "   428                                                             \"`max_features='auto'` has been deprecated in 1.1 \"\n",
       "   429                                                             \"and will be removed in 1.3. To keep the past behaviour, \"\n",
       "   430                                                             \"explicitly set `max_features='sqrt'` or remove this \"\n",
       "   431                                                             \"parameter as it is also the default value for \"\n",
       "   432                                                             \"RandomForestClassifiers and ExtraTreesClassifiers.\",\n",
       "   433                                                             FutureWarning,\n",
       "   434                                                         )\n",
       "   435                                         \n",
       "   436   1841.0 MiB      0.0 MiB           1           if not self.bootstrap and self.oob_score:\n",
       "   437                                                     raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
       "   438                                         \n",
       "   439   1841.0 MiB      0.0 MiB           1           random_state = check_random_state(self.random_state)\n",
       "   440                                         \n",
       "   441   1841.0 MiB      0.0 MiB           1           if not self.warm_start or not hasattr(self, \"estimators_\"):\n",
       "   442                                                     # Free allocated memory, if any\n",
       "   443   1841.0 MiB      0.0 MiB           1               self.estimators_ = []\n",
       "   444                                         \n",
       "   445   1841.0 MiB      0.0 MiB           1           n_more_estimators = self.n_estimators - len(self.estimators_)\n",
       "   446                                         \n",
       "   447   1841.0 MiB      0.0 MiB           1           if n_more_estimators < 0:\n",
       "   448                                                     raise ValueError(\n",
       "   449                                                         \"n_estimators=%d must be larger or equal to \"\n",
       "   450                                                         \"len(estimators_)=%d when warm_start==True\"\n",
       "   451                                                         % (self.n_estimators, len(self.estimators_))\n",
       "   452                                                     )\n",
       "   453                                         \n",
       "   454   1841.0 MiB      0.0 MiB           1           elif n_more_estimators == 0:\n",
       "   455                                                     warn(\n",
       "   456                                                         \"Warm-start fitting without increasing n_estimators does not \"\n",
       "   457                                                         \"fit new trees.\"\n",
       "   458                                                     )\n",
       "   459                                                 else:\n",
       "   460   1841.0 MiB      0.0 MiB           1               if self.warm_start and len(self.estimators_) > 0:\n",
       "   461                                                         # We draw from the random state to get the random state we\n",
       "   462                                                         # would have got if we hadn't used a warm_start.\n",
       "   463                                                         random_state.randint(MAX_INT, size=len(self.estimators_))\n",
       "   464                                         \n",
       "   465   1841.0 MiB      0.0 MiB         504               trees = [\n",
       "   466   1841.0 MiB      0.0 MiB         500                   self._make_estimator(append=False, random_state=random_state)\n",
       "   467   1841.0 MiB      0.0 MiB         501                   for i in range(n_more_estimators)\n",
       "   468                                                     ]\n",
       "   469                                         \n",
       "   470                                                     # Parallel loop: we prefer the threading backend as the Cython code\n",
       "   471                                                     # for fitting the trees is internally releasing the Python GIL\n",
       "   472                                                     # making threading more efficient than multiprocessing in\n",
       "   473                                                     # that case. However, for joblib 0.12+ we respect any\n",
       "   474                                                     # parallel_backend contexts set at a higher level,\n",
       "   475                                                     # since correctness does not rely on using threads.\n",
       "   476   1938.2 MiB     97.0 MiB           3               trees = Parallel(\n",
       "   477   1841.0 MiB      0.0 MiB           1                   n_jobs=self.n_jobs,\n",
       "   478   1841.0 MiB      0.0 MiB           1                   verbose=self.verbose,\n",
       "   479   1841.0 MiB      0.0 MiB           1                   prefer=\"threads\",\n",
       "   480   1841.2 MiB      0.0 MiB          19               )(\n",
       "   481   1841.2 MiB      0.2 MiB          47                   delayed(_parallel_build_trees)(\n",
       "   482   1841.2 MiB      0.0 MiB          16                       t,\n",
       "   483   1841.2 MiB      0.0 MiB          16                       self.bootstrap,\n",
       "   484   1841.2 MiB      0.0 MiB          16                       X,\n",
       "   485   1841.2 MiB      0.0 MiB          16                       y,\n",
       "   486   1841.2 MiB      0.0 MiB          16                       sample_weight,\n",
       "   487   1841.2 MiB      0.0 MiB          16                       i,\n",
       "   488   1841.2 MiB      0.0 MiB          16                       len(trees),\n",
       "   489   1841.2 MiB      0.0 MiB          16                       verbose=self.verbose,\n",
       "   490   1841.2 MiB      0.0 MiB          16                       class_weight=self.class_weight,\n",
       "   491   1841.2 MiB      0.0 MiB          16                       n_samples_bootstrap=n_samples_bootstrap,\n",
       "   492                                                         )\n",
       "   493   1841.2 MiB      0.0 MiB          17                   for i, t in enumerate(trees)\n",
       "   494                                                     )\n",
       "   495                                         \n",
       "   496                                                     # Collect newly grown trees\n",
       "   497   1938.2 MiB      0.0 MiB           1               self.estimators_.extend(trees)\n",
       "   498                                         \n",
       "   499   1938.2 MiB      0.0 MiB           1           if self.oob_score:\n",
       "   500                                                     y_type = type_of_target(y)\n",
       "   501                                                     if y_type in (\"multiclass-multioutput\", \"unknown\"):\n",
       "   502                                                         # FIXME: we could consider to support multiclass-multioutput if\n",
       "   503                                                         # we introduce or reuse a constructor parameter (e.g.\n",
       "   504                                                         # oob_score) allowing our user to pass a callable defining the\n",
       "   505                                                         # scoring strategy on OOB sample.\n",
       "   506                                                         raise ValueError(\n",
       "   507                                                             \"The type of target cannot be used to compute OOB \"\n",
       "   508                                                             f\"estimates. Got {y_type} while only the following are \"\n",
       "   509                                                             \"supported: continuous, continuous-multioutput, binary, \"\n",
       "   510                                                             \"multiclass, multilabel-indicator.\"\n",
       "   511                                                         )\n",
       "   512                                         \n",
       "   513                                                     if callable(self.oob_score):\n",
       "   514                                                         self._set_oob_score_and_attributes(\n",
       "   515                                                             X, y, scoring_function=self.oob_score\n",
       "   516                                                         )\n",
       "   517                                                     else:\n",
       "   518                                                         self._set_oob_score_and_attributes(X, y)\n",
       "   519                                         \n",
       "   520                                                 # Decapsulate classes_ attributes\n",
       "   521   1938.2 MiB      0.0 MiB           1           if hasattr(self, \"classes_\") and self.n_outputs_ == 1:\n",
       "   522   1938.2 MiB      0.0 MiB           1               self.n_classes_ = self.n_classes_[0]\n",
       "   523   1938.2 MiB      0.0 MiB           1               self.classes_ = self.classes_[0]\n",
       "   524                                         \n",
       "   525   1938.2 MiB      0.0 MiB           1           return self"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mprun -f estimator.fit estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca20891-5a48-4a73-aec8-6ec00b96c423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         671067 function calls (659030 primitive calls) in 85.823 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "   List reduced from 394 to 5 due to restriction <'_forest'>\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    0.051    0.051   85.817   85.817 _forest.py:313(fit)\n",
       "        1    0.000    0.000    0.117    0.117 _forest.py:465(<listcomp>)\n",
       "        1    0.000    0.000    0.003    0.003 _forest.py:764(_validate_y_class_weight)\n",
       "       16    0.000    0.000    0.000    0.000 _forest.py:480(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 _forest.py:90(_get_n_samples_bootstrap)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%prun -l _forest estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af68dfdc-688e-4e8e-8f0e-ddb6a867880a",
   "metadata": {},
   "source": [
    "# Main Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0ad11a-76c7-4f3f-b3cd-ef8283366d2e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /Users/adam2392/Documents/scikit-learn/sklearn/ensemble/_forest.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "   313   1494.8 MiB   1494.8 MiB           1       def fit(self, X, y, sample_weight=None):\n",
       "   314                                                 \"\"\"\n",
       "   315                                                 Build a forest of trees from the training set (X, y).\n",
       "   316                                         \n",
       "   317                                                 Parameters\n",
       "   318                                                 ----------\n",
       "   319                                                 X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
       "   320                                                     The training input samples. Internally, its dtype will be converted\n",
       "   321                                                     to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
       "   322                                                     converted into a sparse ``csc_matrix``.\n",
       "   323                                         \n",
       "   324                                                 y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
       "   325                                                     The target values (class labels in classification, real numbers in\n",
       "   326                                                     regression).\n",
       "   327                                         \n",
       "   328                                                 sample_weight : array-like of shape (n_samples,), default=None\n",
       "   329                                                     Sample weights. If None, then samples are equally weighted. Splits\n",
       "   330                                                     that would create child nodes with net zero or negative weight are\n",
       "   331                                                     ignored while searching for a split in each node. In the case of\n",
       "   332                                                     classification, splits are also ignored if they would result in any\n",
       "   333                                                     single class carrying a negative weight in either child node.\n",
       "   334                                         \n",
       "   335                                                 Returns\n",
       "   336                                                 -------\n",
       "   337                                                 self : object\n",
       "   338                                                     Fitted estimator.\n",
       "   339                                                 \"\"\"\n",
       "   340   1494.8 MiB      0.0 MiB           1           self._validate_params()\n",
       "   341                                         \n",
       "   342                                                 # Validate or convert input data\n",
       "   343   1494.8 MiB      0.0 MiB           1           if issparse(y):\n",
       "   344                                                     raise ValueError(\"sparse multilabel-indicator for y is not supported.\")\n",
       "   345   1494.8 MiB      0.0 MiB           2           X, y = self._validate_data(\n",
       "   346   1494.8 MiB      0.0 MiB           1               X, y, multi_output=True, accept_sparse=\"csc\", dtype=DTYPE\n",
       "   347                                                 )\n",
       "   348   1494.8 MiB      0.0 MiB           1           if sample_weight is not None:\n",
       "   349                                                     sample_weight = _check_sample_weight(sample_weight, X)\n",
       "   350                                         \n",
       "   351   1494.8 MiB      0.0 MiB           1           if issparse(X):\n",
       "   352                                                     # Pre-sort indices to avoid that each individual tree of the\n",
       "   353                                                     # ensemble sorts the indices.\n",
       "   354                                                     X.sort_indices()\n",
       "   355   1494.8 MiB      0.0 MiB           1           elif not X.flags.fortran:\n",
       "   356                                                     # if X is not fortran, then make a copy here and make sure it is fortran\n",
       "   357   1838.1 MiB    343.3 MiB           1               X = np.asfortranarray(X, dtype=DTYPE)\n",
       "   358                                         \n",
       "   359   1838.1 MiB      0.0 MiB           1           y = np.atleast_1d(y)\n",
       "   360   1838.1 MiB      0.0 MiB           1           if y.ndim == 2 and y.shape[1] == 1:\n",
       "   361                                                     warn(\n",
       "   362                                                         \"A column-vector y was passed when a 1d array was\"\n",
       "   363                                                         \" expected. Please change the shape of y to \"\n",
       "   364                                                         \"(n_samples,), for example using ravel().\",\n",
       "   365                                                         DataConversionWarning,\n",
       "   366                                                         stacklevel=2,\n",
       "   367                                                     )\n",
       "   368                                         \n",
       "   369   1838.1 MiB      0.0 MiB           1           if y.ndim == 1:\n",
       "   370                                                     # reshape is necessary to preserve the data contiguity against vs\n",
       "   371                                                     # [:, np.newaxis] that does not.\n",
       "   372   1838.1 MiB      0.0 MiB           1               y = np.reshape(y, (-1, 1))\n",
       "   373                                         \n",
       "   374   1838.1 MiB      0.0 MiB           1           if self.criterion == \"poisson\":\n",
       "   375                                                     if np.any(y < 0):\n",
       "   376                                                         raise ValueError(\n",
       "   377                                                             \"Some value(s) of y are negative which is \"\n",
       "   378                                                             \"not allowed for Poisson regression.\"\n",
       "   379                                                         )\n",
       "   380                                                     if np.sum(y) <= 0:\n",
       "   381                                                         raise ValueError(\n",
       "   382                                                             \"Sum of y is not strictly positive which \"\n",
       "   383                                                             \"is necessary for Poisson regression.\"\n",
       "   384                                                         )\n",
       "   385                                         \n",
       "   386   1838.1 MiB      0.0 MiB           1           self.n_outputs_ = y.shape[1]\n",
       "   387                                         \n",
       "   388   1841.0 MiB      2.9 MiB           1           y, expanded_class_weight = self._validate_y_class_weight(y)\n",
       "   389                                         \n",
       "   390   1841.0 MiB      0.0 MiB           1           if getattr(y, \"dtype\", None) != DOUBLE or not y.flags.contiguous:\n",
       "   391   1841.0 MiB      0.0 MiB           1               y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
       "   392                                         \n",
       "   393   1841.0 MiB      0.0 MiB           1           if expanded_class_weight is not None:\n",
       "   394                                                     if sample_weight is not None:\n",
       "   395                                                         sample_weight = sample_weight * expanded_class_weight\n",
       "   396                                                     else:\n",
       "   397                                                         sample_weight = expanded_class_weight\n",
       "   398                                         \n",
       "   399   1841.0 MiB      0.0 MiB           1           if not self.bootstrap and self.max_samples is not None:\n",
       "   400                                                     raise ValueError(\n",
       "   401                                                         \"`max_sample` cannot be set if `bootstrap=False`. \"\n",
       "   402                                                         \"Either switch to `bootstrap=True` or set \"\n",
       "   403                                                         \"`max_sample=None`.\"\n",
       "   404                                                     )\n",
       "   405   1841.0 MiB      0.0 MiB           1           elif self.bootstrap:\n",
       "   406   1841.0 MiB      0.0 MiB           2               n_samples_bootstrap = _get_n_samples_bootstrap(\n",
       "   407   1841.0 MiB      0.0 MiB           1                   n_samples=X.shape[0], max_samples=self.max_samples\n",
       "   408                                                     )\n",
       "   409                                                 else:\n",
       "   410                                                     n_samples_bootstrap = None\n",
       "   411                                         \n",
       "   412   1841.0 MiB      0.0 MiB           1           self._validate_estimator()\n",
       "   413   1841.0 MiB      0.0 MiB           1           if isinstance(self, (RandomForestRegressor, ExtraTreesRegressor)):\n",
       "   414                                                     # TODO(1.3): Remove \"auto\"\n",
       "   415                                                     if self.max_features == \"auto\":\n",
       "   416                                                         warn(\n",
       "   417                                                             \"`max_features='auto'` has been deprecated in 1.1 \"\n",
       "   418                                                             \"and will be removed in 1.3. To keep the past behaviour, \"\n",
       "   419                                                             \"explicitly set `max_features=1.0` or remove this \"\n",
       "   420                                                             \"parameter as it is also the default value for \"\n",
       "   421                                                             \"RandomForestRegressors and ExtraTreesRegressors.\",\n",
       "   422                                                             FutureWarning,\n",
       "   423                                                         )\n",
       "   424   1841.0 MiB      0.0 MiB           1           elif isinstance(self, (RandomForestClassifier, ExtraTreesClassifier)):\n",
       "   425                                                     # TODO(1.3): Remove \"auto\"\n",
       "   426   1841.0 MiB      0.0 MiB           1               if self.max_features == \"auto\":\n",
       "   427                                                         warn(\n",
       "   428                                                             \"`max_features='auto'` has been deprecated in 1.1 \"\n",
       "   429                                                             \"and will be removed in 1.3. To keep the past behaviour, \"\n",
       "   430                                                             \"explicitly set `max_features='sqrt'` or remove this \"\n",
       "   431                                                             \"parameter as it is also the default value for \"\n",
       "   432                                                             \"RandomForestClassifiers and ExtraTreesClassifiers.\",\n",
       "   433                                                             FutureWarning,\n",
       "   434                                                         )\n",
       "   435                                         \n",
       "   436   1841.0 MiB      0.0 MiB           1           if not self.bootstrap and self.oob_score:\n",
       "   437                                                     raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
       "   438                                         \n",
       "   439   1841.0 MiB      0.0 MiB           1           random_state = check_random_state(self.random_state)\n",
       "   440                                         \n",
       "   441   1841.0 MiB      0.0 MiB           1           if not self.warm_start or not hasattr(self, \"estimators_\"):\n",
       "   442                                                     # Free allocated memory, if any\n",
       "   443   1841.0 MiB      0.0 MiB           1               self.estimators_ = []\n",
       "   444                                         \n",
       "   445   1841.0 MiB      0.0 MiB           1           n_more_estimators = self.n_estimators - len(self.estimators_)\n",
       "   446                                         \n",
       "   447   1841.0 MiB      0.0 MiB           1           if n_more_estimators < 0:\n",
       "   448                                                     raise ValueError(\n",
       "   449                                                         \"n_estimators=%d must be larger or equal to \"\n",
       "   450                                                         \"len(estimators_)=%d when warm_start==True\"\n",
       "   451                                                         % (self.n_estimators, len(self.estimators_))\n",
       "   452                                                     )\n",
       "   453                                         \n",
       "   454   1841.0 MiB      0.0 MiB           1           elif n_more_estimators == 0:\n",
       "   455                                                     warn(\n",
       "   456                                                         \"Warm-start fitting without increasing n_estimators does not \"\n",
       "   457                                                         \"fit new trees.\"\n",
       "   458                                                     )\n",
       "   459                                                 else:\n",
       "   460   1841.0 MiB      0.0 MiB           1               if self.warm_start and len(self.estimators_) > 0:\n",
       "   461                                                         # We draw from the random state to get the random state we\n",
       "   462                                                         # would have got if we hadn't used a warm_start.\n",
       "   463                                                         random_state.randint(MAX_INT, size=len(self.estimators_))\n",
       "   464                                         \n",
       "   465   1841.0 MiB      0.0 MiB         504               trees = [\n",
       "   466   1841.0 MiB      0.0 MiB         500                   self._make_estimator(append=False, random_state=random_state)\n",
       "   467   1841.0 MiB      0.0 MiB         501                   for i in range(n_more_estimators)\n",
       "   468                                                     ]\n",
       "   469                                         \n",
       "   470                                                     # Parallel loop: we prefer the threading backend as the Cython code\n",
       "   471                                                     # for fitting the trees is internally releasing the Python GIL\n",
       "   472                                                     # making threading more efficient than multiprocessing in\n",
       "   473                                                     # that case. However, for joblib 0.12+ we respect any\n",
       "   474                                                     # parallel_backend contexts set at a higher level,\n",
       "   475                                                     # since correctness does not rely on using threads.\n",
       "   476   1938.2 MiB     97.0 MiB           3               trees = Parallel(\n",
       "   477   1841.0 MiB      0.0 MiB           1                   n_jobs=self.n_jobs,\n",
       "   478   1841.0 MiB      0.0 MiB           1                   verbose=self.verbose,\n",
       "   479   1841.0 MiB      0.0 MiB           1                   prefer=\"threads\",\n",
       "   480   1841.2 MiB      0.0 MiB          19               )(\n",
       "   481   1841.2 MiB      0.2 MiB          47                   delayed(_parallel_build_trees)(\n",
       "   482   1841.2 MiB      0.0 MiB          16                       t,\n",
       "   483   1841.2 MiB      0.0 MiB          16                       self.bootstrap,\n",
       "   484   1841.2 MiB      0.0 MiB          16                       X,\n",
       "   485   1841.2 MiB      0.0 MiB          16                       y,\n",
       "   486   1841.2 MiB      0.0 MiB          16                       sample_weight,\n",
       "   487   1841.2 MiB      0.0 MiB          16                       i,\n",
       "   488   1841.2 MiB      0.0 MiB          16                       len(trees),\n",
       "   489   1841.2 MiB      0.0 MiB          16                       verbose=self.verbose,\n",
       "   490   1841.2 MiB      0.0 MiB          16                       class_weight=self.class_weight,\n",
       "   491   1841.2 MiB      0.0 MiB          16                       n_samples_bootstrap=n_samples_bootstrap,\n",
       "   492                                                         )\n",
       "   493   1841.2 MiB      0.0 MiB          17                   for i, t in enumerate(trees)\n",
       "   494                                                     )\n",
       "   495                                         \n",
       "   496                                                     # Collect newly grown trees\n",
       "   497   1938.2 MiB      0.0 MiB           1               self.estimators_.extend(trees)\n",
       "   498                                         \n",
       "   499   1938.2 MiB      0.0 MiB           1           if self.oob_score:\n",
       "   500                                                     y_type = type_of_target(y)\n",
       "   501                                                     if y_type in (\"multiclass-multioutput\", \"unknown\"):\n",
       "   502                                                         # FIXME: we could consider to support multiclass-multioutput if\n",
       "   503                                                         # we introduce or reuse a constructor parameter (e.g.\n",
       "   504                                                         # oob_score) allowing our user to pass a callable defining the\n",
       "   505                                                         # scoring strategy on OOB sample.\n",
       "   506                                                         raise ValueError(\n",
       "   507                                                             \"The type of target cannot be used to compute OOB \"\n",
       "   508                                                             f\"estimates. Got {y_type} while only the following are \"\n",
       "   509                                                             \"supported: continuous, continuous-multioutput, binary, \"\n",
       "   510                                                             \"multiclass, multilabel-indicator.\"\n",
       "   511                                                         )\n",
       "   512                                         \n",
       "   513                                                     if callable(self.oob_score):\n",
       "   514                                                         self._set_oob_score_and_attributes(\n",
       "   515                                                             X, y, scoring_function=self.oob_score\n",
       "   516                                                         )\n",
       "   517                                                     else:\n",
       "   518                                                         self._set_oob_score_and_attributes(X, y)\n",
       "   519                                         \n",
       "   520                                                 # Decapsulate classes_ attributes\n",
       "   521   1938.2 MiB      0.0 MiB           1           if hasattr(self, \"classes_\") and self.n_outputs_ == 1:\n",
       "   522   1938.2 MiB      0.0 MiB           1               self.n_classes_ = self.n_classes_[0]\n",
       "   523   1938.2 MiB      0.0 MiB           1               self.classes_ = self.classes_[0]\n",
       "   524                                         \n",
       "   525   1938.2 MiB      0.0 MiB           1           return self"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mprun -f estimator.fit estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f2f30bf-5d4b-4dcf-91f2-e6035ffe1b64",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         671067 function calls (659030 primitive calls) in 85.823 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "   List reduced from 394 to 5 due to restriction <'_forest'>\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    0.051    0.051   85.817   85.817 _forest.py:313(fit)\n",
       "        1    0.000    0.000    0.117    0.117 _forest.py:465(<listcomp>)\n",
       "        1    0.000    0.000    0.003    0.003 _forest.py:764(_validate_y_class_weight)\n",
       "       16    0.000    0.000    0.000    0.000 _forest.py:480(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 _forest.py:90(_get_n_samples_bootstrap)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%prun -l _forest estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ecd88-8b47-4c5b-99d5-2a60dd59368d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-devm1",
   "language": "python",
   "name": "sklearn-devm1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
