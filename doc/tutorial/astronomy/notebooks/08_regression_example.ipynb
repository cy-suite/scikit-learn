{
 "metadata": {
  "name": "08_regression_example"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Regression Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As with the previous example, this notebook assumes that the current\n",
      "working directory is in the scikit-learn tutorial directory where\n",
      "the notebook is stored. In the folder\n",
      "\n",
      "     ../data/sdss_photoz\n",
      "\n",
      "there is a script fetch_data.py which will download the colors of 400,000+ galaxies from the Sloan Digital Sky Survey. This script also includes a python implementation of the SQL query used to construct this data. This template can be modified to download more features if desired. Before executing the example below, run fetch_data.py to download the colors and redshifts.\n",
      "\n",
      "If you're using a different directory structure, then the DATA_HOME variable in the following script should be set accordingly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "DATA_HOME = os.path.abspath('../data/sdss_photoz/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we will load this data, shuffle it in preparation for later, and arrange the colors in an array of shape (n_samples, n_features):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "data = np.load(os.path.join(DATA_HOME,'sdss_photoz.npy'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data is in a record array, as in the classification example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print data.dtype.names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll set up our data matrix ``X`` and redshift ``z``"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = len(data)\n",
      "X = np.zeros((N, 4))\n",
      "X[:, 0] = data['u'] - data['g']\n",
      "X[:, 1] = data['g'] - data['r']\n",
      "X[:, 2] = data['r'] - data['i']\n",
      "X[:, 3] = data['i'] - data['z']\n",
      "z = data['redshift']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we\u2019ll split the data into two samples: a training sample and a test sample which we\u2019ll use to evaluate our training:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Ntrain = 3 * N / 4\n",
      "Xtrain = X[:Ntrain]\n",
      "ztrain = z[:Ntrain]\n",
      "Xtest = X[Ntrain:]\n",
      "ztest = z[Ntrain:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we\u2019ll use the scikit-learn ``DecisionTreeRegressor`` method\n",
      "to train a model and predict redshifts for the test set based\n",
      "on a 20-level decision tree:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeRegressor\n",
      "clf = DecisionTreeRegressor(max_depth=20)\n",
      "clf.fit(Xtrain, ztrain)\n",
      "zpred = clf.predict(Xtest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To judge the efficacy of prediction, we can compute the\n",
      "root-mean-square (RMS) difference between the true and predicted values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rms = np.sqrt(np.mean((ztest - zpred) ** 2))\n",
      "print rms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our RMS error is about 0.22. This is pretty good for such an unsophisticated\n",
      "learning algorithm, but better algorithms can improve on this. The biggest\n",
      "issue here are the catastrophic errors, where the predicted redshift is\n",
      "extremely far from the prediction:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Number of test samples:       \", len(ztest)\n",
      "print \"Number of catastrophic errors:\", np.sum(abs(ztest - zpred) > 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "About 1.5% of objects have redshift estimates which are off by greater than 1.\n",
      "This sort of error in redshift determination is very problematic for\n",
      "high-precision cosmological studies. This can be seen in a scatter plot of\n",
      "the predicted redshift versus the true redshift for the test data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ax = pl.axes()\n",
      "\n",
      "pl.scatter(ztest, zpred, c='k', lw=0, s=4)\n",
      "axis_lim = np.array([0, 2.5])\n",
      "\n",
      "# plot the true redshift\n",
      "pl.plot(axis_lim, axis_lim, '--k')\n",
      "\n",
      "# plot +/- the rms\n",
      "pl.plot(axis_lim, axis_lim + rms, '--r')  \n",
      "pl.plot(axis_lim, axis_lim - rms, '--r')\n",
      "pl.xlim(axis_lim)\n",
      "pl.ylim(axis_lim)\n",
      "\n",
      "pl.title('Photo-z: Decision Tree Regression')\n",
      "pl.xlabel(r'$\\mathrm{z_{true}}$', fontsize=14)\n",
      "pl.ylabel(r'$\\mathrm{z_{phot}}$', fontsize=14)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The true and predicted redshifts of 102,798 SDSS galaxies, using a simple decision tree regressor. Notice the presece of catastrophic outliers: those galaxies whose predicted redshifts are extremely far from the true value.\n",
      "\n",
      "Later, in Exercise #2, we will attempt to improve on this by optimizing the parameters of the decision tree.\n",
      "\n",
      "In practice, the solutions to the photometric redshift problem can benefit from approaches that use physical intuition as well as machine learning tools. For example, some solutions involve the use of libraries of synthetic galaxy spectra which are known to be representative of the true galaxy distribution. This extra information can be used either directly, in a physically motivated analysis, or can be used to generate a larger suite of artificial training instances for a pure machine learning approach."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}