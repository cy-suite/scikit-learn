{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "metadata": {
        "id": "2Awb1HjzjRUE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Fashion MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "t91iRJcmncqu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data to include the channel dimension (28, 28, 1)\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "0wKu2urynciS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert grayscale to RGB by repeating the single channel three times\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "m9MEeH_mnbsA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data to [0, 1]\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "GZVghJeVnbeL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)  # Convert to one-hot encoding\n",
        "y_test = to_categorical(y_test, 10)    # Convert to one-hot encoding\n"
      ],
      "metadata": {
        "id": "JYUtVHmBtrFi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a preprocessing function to resize and convert images to RGB on the fly\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.grayscale_to_rgb(image)\n",
        "    image = tf.image.resize(image, (224, 224))  # Resize on the fly\n",
        "    return image, label\n"
      ],
      "metadata": {
        "id": "jUB-bs5jnbSd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataset to tf.data.Dataset for better memory management\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
      ],
      "metadata": {
        "id": "PgVk59GosuXN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing in batches\n",
        "train_ds = train_ds.map(preprocess).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_ds = test_ds.map(preprocess).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "dOVlFyD3syTw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "BT1OLT5ss1Zh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet50 model without the top (the fully connected layers)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "tKf-TxJFs4rk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the base model to prevent its weights from being updated during training\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "txyyD2Sqs8ue"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add custom layers on top of the base model for Fashion MNIST\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Use global average pooling instead of flattening\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(10, activation='softmax')(x)  # 10 classes in Fashion MNIST\n"
      ],
      "metadata": {
        "id": "tw8D6RK6tBtB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=outputs)"
      ],
      "metadata": {
        "id": "2TDPqK7RtFM4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nMcI1r8itIjk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with the dataset pipeline\n",
        "model.fit(train_ds, validation_data=test_ds, epochs=10)"
      ],
      "metadata": {
        "id": "AxZKi2-ItMIn",
        "outputId": "d7624cd5-f38f-4e95-9a34-804f5da85225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 104ms/step - accuracy: 0.3803 - loss: 1.6750 - val_accuracy: 0.6429 - val_loss: 0.9861\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 103ms/step - accuracy: 0.6106 - loss: 1.0535 - val_accuracy: 0.6734 - val_loss: 0.8858\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 103ms/step - accuracy: 0.6426 - loss: 0.9658 - val_accuracy: 0.7137 - val_loss: 0.7950\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 103ms/step - accuracy: 0.6597 - loss: 0.9154 - val_accuracy: 0.7189 - val_loss: 0.7836\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 103ms/step - accuracy: 0.6697 - loss: 0.8860 - val_accuracy: 0.7299 - val_loss: 0.7486\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 94ms/step - accuracy: 0.6816 - loss: 0.8554 - val_accuracy: 0.7301 - val_loss: 0.7379\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 94ms/step - accuracy: 0.6842 - loss: 0.8388 - val_accuracy: 0.7313 - val_loss: 0.7191\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 94ms/step - accuracy: 0.6917 - loss: 0.8306 - val_accuracy: 0.7486 - val_loss: 0.6962\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 95ms/step - accuracy: 0.6956 - loss: 0.8173 - val_accuracy: 0.7522 - val_loss: 0.6969\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 103ms/step - accuracy: 0.6922 - loss: 0.8277 - val_accuracy: 0.7314 - val_loss: 0.7212\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f338bf17760>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "k1FGLRYitRME",
        "outputId": "010e21ce-d166-4af7-c4b4-46612d09b781",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 81ms/step - accuracy: 0.7322 - loss: 0.7229\n",
            "Test Accuracy: 0.7314000129699707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_MZgPdD2PSy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}